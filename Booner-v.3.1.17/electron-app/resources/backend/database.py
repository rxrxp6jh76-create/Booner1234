"""
SQLite Database Manager f√ºr Desktop Trading App
Ersetzt MongoDB mit einer lokalen SQLite Datenbank
"""

import sqlite3
import aiosqlite
import json
import logging
from pathlib import Path
from datetime import datetime, timezone
from typing import Optional, List, Dict, Any
import os
import uuid
import asyncio

logger = logging.getLogger(__name__)

# Datenbankpfad - NIEMALS im App-Bundle (read-only unter macOS!)
# Pr√ºfe ob wir in einer Electron App laufen
def get_db_path():
    # 1. Pr√ºfe Environment Variable (gesetzt von main.js)
    env_path = os.getenv('SQLITE_DB_PATH')
    if env_path:
        # Stelle sicher dass Verzeichnis existiert
        db_dir = Path(env_path).parent
        db_dir.mkdir(parents=True, exist_ok=True)
        logger.info(f"‚úÖ Using DB path from SQLITE_DB_PATH: {env_path}")
        return env_path
    
    # 2. Fallback: Pr√ºfe ob wir im App-Bundle sind (read-only!)
    current_path = Path(__file__).parent
    if '/Applications/' in str(current_path) or '.app/Contents/Resources' in str(current_path):
        # WIR SIND IM APP-BUNDLE! Nutze User-Verzeichnis
        # WICHTIG: Nutze den gleichen Namen wie electron-app (kleingeschrieben!)
        user_data_dir = Path.home() / 'Library' / 'Application Support' / 'booner-trade' / 'database'
        user_data_dir.mkdir(parents=True, exist_ok=True)
        db_path = user_data_dir / 'trading.db'
        logger.warning(f"‚ö†Ô∏è  App-Bundle detected! Using user directory: {db_path}")
        return str(db_path)
    
    # 3. Development: Nutze Backend-Verzeichnis
    dev_path = str(current_path / 'trading.db')
    logger.info(f"üìÅ Using development DB path: {dev_path}")
    return dev_path

# WICHTIG: Nicht beim Import aufrufen, sondern lazy evaluation!
DB_PATH = None

def get_current_db_path():
    """Gibt den aktuellen DB-Pfad zur√ºck (wird zur Laufzeit ermittelt)"""
    global DB_PATH
    if DB_PATH is None:
        DB_PATH = get_db_path()
    return DB_PATH


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Distributed Locks (SQLite-basiert)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê


async def _configure_lock_connection(conn: aiosqlite.Connection):
    """Setzt pragmas f√ºr schnelle Lock-Operationen."""
    await conn.execute("PRAGMA journal_mode=WAL")
    await conn.execute("PRAGMA busy_timeout = 15000")
    await conn.execute("PRAGMA synchronous = NORMAL")
    await conn.execute("PRAGMA temp_store = MEMORY")

async def acquire_lock(lock_key: str, owner: str = None, ttl_seconds: int = 180) -> Optional[str]:
    """Versucht einen verteilten Lock zu setzen. Gibt owner zur√ºck oder None."""
    owner = owner or str(uuid.uuid4())
    db_path = get_current_db_path()
    for attempt in range(3):
        try:
            async with aiosqlite.connect(db_path, timeout=15, isolation_level=None) as conn:
                await _configure_lock_connection(conn)
                now_iso = datetime.now(timezone.utc).isoformat()
                # Entferne veraltete Locks
                await conn.execute(
                    "DELETE FROM trade_locks WHERE lock_key = ? AND (strftime('%s','now') - strftime('%s', created_at)) > ?",
                    (lock_key, ttl_seconds)
                )
                # Versuche Lock zu setzen
                cur = await conn.execute(
                    "INSERT OR IGNORE INTO trade_locks(lock_key, owner, created_at) VALUES (?, ?, ?)",
                    (lock_key, owner, now_iso)
                )
                await conn.commit()
                if cur.rowcount == 1:
                    return owner
                return None
        except sqlite3.OperationalError as e:
            # Kurzer Backoff reduziert Wait-Stau bei hoher Parallelit√§t
            if attempt < 2:
                await asyncio.sleep(0.05 * (attempt + 1))
                continue
            logger.error(f"Lock acquire failed for {lock_key} after retries: {e}")
            return None
        except Exception as e:
            logger.error(f"Lock acquire failed for {lock_key}: {e}")
            return None


async def release_lock(lock_key: str, owner: str) -> bool:
    """Entfernt den Lock nur, wenn er dem Owner geh√∂rt."""
    db_path = get_current_db_path()
    try:
        async with aiosqlite.connect(db_path, timeout=15, isolation_level=None) as conn:
            await _configure_lock_connection(conn)
            cur = await conn.execute(
                "DELETE FROM trade_locks WHERE lock_key = ? AND owner = ?",
                (lock_key, owner)
            )
            await conn.commit()
            return cur.rowcount > 0
    except Exception as e:
        logger.error(f"Lock release failed for {lock_key}: {e}")
        return False

class Database:
    """SQLite Database Manager mit async Support"""
    
    def __init__(self, db_path: str = None):
        # Hole DB-Pfad zur Laufzeit, nicht beim Import!
        self.db_path = db_path if db_path else get_current_db_path()
        self._conn = None
        self._lock = None  # V2.3.30: asyncio.Lock f√ºr Thread-Safety
        logger.info(f"üóÑÔ∏è  Database initialized with path: {self.db_path}")
        
    async def connect(self):
        """Verbindung zur Datenbank herstellen mit optimierten Settings"""
        import asyncio
        try:
            # V2.3.30: Create async lock for thread-safety
            if self._lock is None:
                self._lock = asyncio.Lock()
            
            self._conn = await aiosqlite.connect(
                self.db_path,
                timeout=120.0,  # V2.3.30: Erh√∂ht auf 120 Sekunden
                isolation_level=None  # V2.3.30: Autocommit mode f√ºr bessere Concurrency
            )
            # Enable WAL mode for better concurrency
            await self._conn.execute("PRAGMA journal_mode=WAL")
            # Enable foreign keys
            await self._conn.execute("PRAGMA foreign_keys = ON")
            # V2.3.30: Erh√∂hter busy_timeout auf 120 Sekunden
            await self._conn.execute("PRAGMA busy_timeout = 120000")
            # Synchronous mode = NORMAL for better performance with WAL
            await self._conn.execute("PRAGMA synchronous = NORMAL")
            # V2.3.30: Gr√∂√üerer Cache f√ºr bessere Performance
            await self._conn.execute("PRAGMA cache_size = -64000")  # 64MB Cache
            # V2.3.30: Temp Store im Memory
            await self._conn.execute("PRAGMA temp_store = MEMORY")
            await self._conn.commit()
            logger.info(f"‚úÖ SQLite verbunden (WAL mode, 120s timeout, 64MB cache): {self.db_path}")
            return self._conn
        except Exception as e:
            logger.error(f"‚ùå SQLite Verbindung fehlgeschlagen: {e}")
            raise
    
    async def execute_with_retry(self, query: str, params: tuple = None, max_retries: int = 5):
        """V2.3.30: Execute query with retry on database locked error"""
        import asyncio
        last_error = None
        
        for attempt in range(max_retries):
            try:
                async with self._lock:
                    if params:
                        result = await self._conn.execute(query, params)
                    else:
                        result = await self._conn.execute(query)
                    await self._conn.commit()
                    return result
            except sqlite3.OperationalError as e:
                if "database is locked" in str(e):
                    last_error = e
                    wait_time = 0.5 * (attempt + 1)  # Exponential backoff
                    logger.warning(f"‚ö†Ô∏è Database locked (attempt {attempt + 1}/{max_retries}), waiting {wait_time}s...")
                    await asyncio.sleep(wait_time)
                else:
                    raise
            except Exception as e:
                raise
        
        logger.error(f"‚ùå Database still locked after {max_retries} attempts")
        raise last_error
    
    async def close(self):
        """Verbindung schlie√üen"""
        if self._conn:
            await self._conn.close()
            self._conn = None
            logger.info("SQLite Verbindung geschlossen")
    
    async def initialize_schema(self):
        """Erstelle alle ben√∂tigten Tabellen"""
        try:
            logger.info("Erstelle SQLite Schema...")
            
            # Trading Settings
            await self._conn.execute("""
                CREATE TABLE IF NOT EXISTS trading_settings (
                    id TEXT PRIMARY KEY,
                    data TEXT NOT NULL,
                    updated_at TEXT NOT NULL
                )
            """)
            
            # Trades
            await self._conn.execute("""
                CREATE TABLE IF NOT EXISTS trades (
                    id TEXT PRIMARY KEY,
                    timestamp TEXT NOT NULL,
                    commodity TEXT NOT NULL,
                    type TEXT NOT NULL,
                    price REAL NOT NULL,
                    quantity REAL DEFAULT 1.0,
                    status TEXT DEFAULT 'OPEN',
                    platform TEXT DEFAULT 'MT5_LIBERTEX',
                    entry_price REAL NOT NULL,
                    exit_price REAL,
                    profit_loss REAL,
                    stop_loss REAL,
                    take_profit REAL,
                    strategy_signal TEXT,
                    closed_at TEXT,
                    mt5_ticket TEXT,
                    strategy TEXT,
                    opened_at TEXT,
                    opened_by TEXT,
                    closed_by TEXT,
                    close_reason TEXT,
                    ai_reasoning TEXT,
                    pillar_scores TEXT
                )
            """)
            
            # V3.0: Add ai_reasoning and pillar_scores columns to existing trades
            try:
                await self._conn.execute("ALTER TABLE trades ADD COLUMN ai_reasoning TEXT")
                logger.info("‚úÖ Added ai_reasoning column to trades table")
            except:
                pass  # Column already exists
            
            try:
                await self._conn.execute("ALTER TABLE trades ADD COLUMN pillar_scores TEXT")
                logger.info("‚úÖ Added pillar_scores column to trades table")
            except:
                pass  # Column already exists
            
            # V3.5: Pillar Weights History Table f√ºr Drift-Tracking
            await self._conn.execute("""
                CREATE TABLE IF NOT EXISTS pillar_weights_history (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    asset TEXT NOT NULL,
                    strategy TEXT NOT NULL,
                    timestamp TEXT NOT NULL,
                    base_signal_weight REAL NOT NULL,
                    trend_confluence_weight REAL NOT NULL,
                    volatility_weight REAL NOT NULL,
                    sentiment_weight REAL NOT NULL,
                    optimization_reason TEXT,
                    trades_analyzed INTEGER DEFAULT 0,
                    win_rate REAL DEFAULT 0.0
                )
            """)
            
            # V3.5: Auditor Log Table f√ºr blockierte Trades
            await self._conn.execute("""
                CREATE TABLE IF NOT EXISTS auditor_log (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT NOT NULL,
                    commodity TEXT NOT NULL,
                    signal TEXT NOT NULL,
                    original_score REAL NOT NULL,
                    adjusted_score REAL NOT NULL,
                    score_adjustment REAL NOT NULL,
                    red_flags TEXT,
                    auditor_reasoning TEXT,
                    blocked INTEGER DEFAULT 0
                )
            """)

            # V3.3: Verteilte Locks (SQLite-basiert, ersetzt Mongo/Redis Locks)
            await self._conn.execute("""
                CREATE TABLE IF NOT EXISTS trade_locks (
                    lock_key TEXT PRIMARY KEY,
                    owner TEXT NOT NULL,
                    created_at TEXT NOT NULL
                )
            """)
            await self._conn.execute("CREATE INDEX IF NOT EXISTS idx_trade_locks_created ON trade_locks(created_at)")
            
            # Index f√ºr schnelle Abfragen
            try:
                await self._conn.execute("""
                    CREATE INDEX IF NOT EXISTS idx_weights_history_asset 
                    ON pillar_weights_history(asset, timestamp)
                """)
                await self._conn.execute("""
                    CREATE INDEX IF NOT EXISTS idx_auditor_log_timestamp 
                    ON auditor_log(timestamp)
                """)
            except:
                pass
            
            # Trade Settings
            await self._conn.execute("""
                CREATE TABLE IF NOT EXISTS trade_settings (
                    trade_id TEXT PRIMARY KEY,
                    stop_loss REAL,
                    take_profit REAL,
                    strategy TEXT,
                    created_at TEXT,
                    entry_price REAL,
                    platform TEXT,
                    commodity TEXT,
                    created_by TEXT,
                    status TEXT DEFAULT 'OPEN',
                    type TEXT
                )
            """)
            
            # Add missing columns to existing tables
            try:
                await self._conn.execute("ALTER TABLE trade_settings ADD COLUMN status TEXT DEFAULT 'OPEN'")
            except:
                pass  # Column already exists
            
            try:
                await self._conn.execute("ALTER TABLE trade_settings ADD COLUMN type TEXT")
            except:
                pass  # Column already exists
            
            # Market Data (Latest) - V2.3.30: Added data_source column
            await self._conn.execute("""
                CREATE TABLE IF NOT EXISTS market_data (
                    commodity TEXT PRIMARY KEY,
                    timestamp TEXT NOT NULL,
                    price REAL NOT NULL,
                    volume REAL,
                    sma_20 REAL,
                    ema_20 REAL,
                    rsi REAL,
                    macd REAL,
                    macd_signal REAL,
                    macd_histogram REAL,
                    trend TEXT,
                    signal TEXT,
                    data_source TEXT
                )
            """)
            
            # V2.3.30: Add data_source column to existing market_data table
            try:
                await self._conn.execute("ALTER TABLE market_data ADD COLUMN data_source TEXT")
                logger.info("‚úÖ Added data_source column to market_data table")
            except:
                pass  # Column already exists
            
            # V3.0.0: Add indicator columns for 4-Pillar Confidence Engine
            v3_columns = [
                ("adx", "REAL"),
                ("atr", "REAL"),
                ("bollinger_upper", "REAL"),
                ("bollinger_lower", "REAL"),
                ("bollinger_width", "REAL")
            ]
            for col_name, col_type in v3_columns:
                try:
                    await self._conn.execute(f"ALTER TABLE market_data ADD COLUMN {col_name} {col_type}")
                    logger.info(f"‚úÖ Added {col_name} column to market_data table")
                except:
                    pass  # Column already exists
            
            # Market Data History
            await self._conn.execute("""
                CREATE TABLE IF NOT EXISTS market_data_history (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    commodity_id TEXT NOT NULL,
                    timestamp TEXT NOT NULL,
                    price REAL NOT NULL,
                    volume REAL,
                    sma_20 REAL,
                    ema_20 REAL,
                    rsi REAL,
                    macd REAL,
                    macd_signal REAL,
                    macd_histogram REAL,
                    trend TEXT,
                    signal TEXT
                )
            """)
            
            # API Keys
            await self._conn.execute("""
                CREATE TABLE IF NOT EXISTS api_keys (
                    id TEXT PRIMARY KEY,
                    metaapi_token TEXT,
                    metaapi_account_id TEXT,
                    metaapi_icmarkets_account_id TEXT,
                    bitpanda_api_key TEXT,
                    bitpanda_email TEXT,
                    finnhub_api_key TEXT,
                    updated_at TEXT NOT NULL
                )
            """)
            
            # Indexes f√ºr Performance
            await self._conn.execute("""
                CREATE INDEX IF NOT EXISTS idx_trades_status ON trades(status)
            """)
            
            await self._conn.execute("""
                CREATE INDEX IF NOT EXISTS idx_trades_mt5_ticket ON trades(mt5_ticket)
            """)
            
            await self._conn.execute("""
                CREATE INDEX IF NOT EXISTS idx_market_history_commodity ON market_data_history(commodity_id, timestamp)
            """)
            
            await self._conn.commit()
            logger.info("‚úÖ SQLite Schema erstellt")
            
        except Exception as e:
            logger.error(f"‚ùå Schema-Erstellung fehlgeschlagen: {e}")
            raise


class TradingSettings:
    """Trading Settings Collection (MongoDB-kompatible API)"""
    
    def __init__(self, db: Database):
        self.db = db
    
    async def find_one(self, query: dict) -> Optional[dict]:
        """Hole Trading Settings"""
        try:
            setting_id = query.get('id', 'trading_settings')
            async with self.db._conn.execute(
                "SELECT data FROM trading_settings WHERE id = ?",
                (setting_id,)
            ) as cursor:
                row = await cursor.fetchone()
                if row:
                    return json.loads(row[0])
                return None
        except Exception as e:
            logger.error(f"Error fetching settings: {e}")
            return None
    
    async def insert_one(self, data: dict):
        """Erstelle neue Settings"""
        try:
            setting_id = data.get('id', 'trading_settings')
            data_json = json.dumps(data)
            await self.db._conn.execute(
                "INSERT INTO trading_settings (id, data, updated_at) VALUES (?, ?, ?)",
                (setting_id, data_json, datetime.now(timezone.utc).isoformat())
            )
            await self.db._conn.commit()
        except Exception as e:
            logger.error(f"Error inserting settings: {e}")
            raise
    
    async def update_one(self, query: dict, update: dict, upsert: bool = False):
        """Update Settings with retry logic for SQLite locking"""
        import asyncio
        
        max_retries = 5
        retry_delay = 0.5
        
        for attempt in range(max_retries):
            try:
                setting_id = query.get('id', 'trading_settings')
                
                # Get current data
                existing = await self.find_one(query)
                
                if existing:
                    # Update existing
                    if '$set' in update:
                        existing.update(update['$set'])
                    data_json = json.dumps(existing)
                    await self.db._conn.execute(
                        "UPDATE trading_settings SET data = ?, updated_at = ? WHERE id = ?",
                        (data_json, datetime.now(timezone.utc).isoformat(), setting_id)
                    )
                elif upsert:
                    # Insert new
                    new_data = update.get('$set', {})
                    new_data['id'] = setting_id
                    await self.insert_one(new_data)
                
                await self.db._conn.commit()
                break  # Success, exit retry loop
                
            except Exception as e:
                error_msg = str(e).lower()
                if ("locked" in error_msg or "busy" in error_msg) and attempt < max_retries - 1:
                    logger.warning(f"Database locked, retry {attempt + 1}/{max_retries}...")
                    await asyncio.sleep(retry_delay)
                    retry_delay *= 1.5  # Exponential backoff
                else:
                    logger.error(f"Error updating settings after {attempt + 1} attempts: {e}")
                    raise


class Trades:
    """Trades Collection (MongoDB-kompatible API)"""
    
    def __init__(self, db: Database):
        self.db = db
    
    async def find(self, query: dict = None, projection: dict = None) -> 'TradesCursor':
        """Find trades"""
        return TradesCursor(self.db, query or {}, projection)
    
    async def find_one(self, query: dict, projection: dict = None) -> Optional[dict]:
        """Find single trade"""
        cursor = await self.find(query, projection)
        results = await cursor.to_list(1)
        return results[0] if results else None
    
    async def insert_one(self, data: dict):
        """Insert new trade with retry logic for SQLite locking"""
        import asyncio
        
        max_retries = 5
        retry_delay = 0.3
        
        for attempt in range(max_retries):
            try:
                # Generate ID if not present
                if 'id' not in data:
                    import uuid
                    data['id'] = str(uuid.uuid4())
                
                # Convert datetime objects to ISO strings
                for key in ['timestamp', 'closed_at', 'opened_at']:
                    if key in data and isinstance(data[key], datetime):
                        data[key] = data[key].isoformat()
                
                # Extract fields
                fields = ['id', 'timestamp', 'commodity', 'type', 'price', 'quantity', 
                         'status', 'platform', 'entry_price', 'exit_price', 'profit_loss',
                         'stop_loss', 'take_profit', 'strategy_signal', 'closed_at', 
                         'mt5_ticket', 'strategy', 'opened_at', 'opened_by', 'closed_by', 
                         'close_reason']
                
                values = [data.get(f) for f in fields]
                placeholders = ','.join(['?' for _ in fields])
                
                await self.db._conn.execute(
                    f"INSERT INTO trades ({','.join(fields)}) VALUES ({placeholders})",
                    values
                )
                await self.db._conn.commit()
                return  # Success
                
            except Exception as e:
                error_msg = str(e).lower()
                if ("locked" in error_msg or "busy" in error_msg) and attempt < max_retries - 1:
                    logger.warning(f"‚ö†Ô∏è DB locked for insert trade (attempt {attempt + 1}/{max_retries}), waiting...")
                    await asyncio.sleep(retry_delay)
                    retry_delay *= 1.5
                else:
                    logger.error(f"Error inserting trade: {e}")
                    raise
    
    async def update_one(self, query: dict, update: dict):
        """Update trade with retry logic for SQLite locking"""
        import asyncio
        
        max_retries = 5
        retry_delay = 0.3
        
        for attempt in range(max_retries):
            try:
                # Build WHERE clause
                where_parts = []
                where_values = []
                for key, value in query.items():
                    where_parts.append(f"{key} = ?")
                    where_values.append(value)
                
                where_clause = " AND ".join(where_parts)
                
                # Build SET clause
                if '$set' in update:
                    set_data = update['$set']
                    set_parts = []
                    set_values = []
                    for key, value in set_data.items():
                        set_parts.append(f"{key} = ?")
                        if isinstance(value, datetime):
                            value = value.isoformat()
                        set_values.append(value)
                    
                    set_clause = ", ".join(set_parts)
                    
                    await self.db._conn.execute(
                        f"UPDATE trades SET {set_clause} WHERE {where_clause}",
                        set_values + where_values
                    )
                    await self.db._conn.commit()
                return  # Success
                
            except Exception as e:
                error_msg = str(e).lower()
                if ("locked" in error_msg or "busy" in error_msg) and attempt < max_retries - 1:
                    logger.warning(f"‚ö†Ô∏è DB locked for trades (attempt {attempt + 1}/{max_retries}), waiting...")
                    await asyncio.sleep(retry_delay)
                    retry_delay *= 1.5
                else:
                    logger.error(f"Error updating trade: {e}")
                    raise
    
    async def delete_one(self, query: dict):
        """Delete trade with retry logic for SQLite locking"""
        import asyncio
        
        max_retries = 5
        retry_delay = 0.5
        
        for attempt in range(max_retries):
            try:
                # Build WHERE clause
                where_parts = []
                where_values = []
                for key, value in query.items():
                    where_parts.append(f"{key} = ?")
                    where_values.append(value)
                
                where_clause = " AND ".join(where_parts)
                
                # Execute delete
                cursor = await self.db._conn.execute(
                    f"DELETE FROM trades WHERE {where_clause}",
                    where_values
                )
                await self.db._conn.commit()
                
                # Return result object
                class DeleteResult:
                    def __init__(self, count):
                        self.deleted_count = count
                
                return DeleteResult(cursor.rowcount)
                
            except Exception as e:
                error_msg = str(e).lower()
                if ("locked" in error_msg or "busy" in error_msg) and attempt < max_retries - 1:
                    logger.warning(f"Database locked while deleting trade, retry {attempt + 1}/{max_retries}...")
                    await asyncio.sleep(retry_delay)
                    retry_delay *= 1.5  # Exponential backoff
                else:
                    logger.error(f"Error deleting trade after {attempt + 1} attempts: {e}")
                    raise
    
    async def delete_many(self, query: dict = None):
        """V2.3.32: Delete multiple trades matching query with retry logic"""
        import asyncio
        
        max_retries = 5
        retry_delay = 0.5
        
        # Return object for compatibility
        class DeleteResult:
            def __init__(self, count):
                self.deleted_count = count
        
        for attempt in range(max_retries):
            try:
                if not query:
                    # Delete all trades
                    cursor = await self.db._conn.execute("DELETE FROM trades")
                else:
                    # Build WHERE clause - handle $or and $exists operators
                    where_parts = []
                    where_values = []
                    
                    if '$or' in query:
                        # Handle $or operator
                        or_parts = []
                        for condition in query['$or']:
                            for key, value in condition.items():
                                if isinstance(value, dict) and '$exists' in value:
                                    if value['$exists'] == False:
                                        or_parts.append(f"({key} IS NULL OR {key} = '')")
                                else:
                                    or_parts.append(f"{key} = ?")
                                    where_values.append(value)
                        where_parts.append(f"({' OR '.join(or_parts)})")
                    else:
                        for key, value in query.items():
                            if isinstance(value, dict) and '$exists' in value:
                                if value['$exists'] == False:
                                    where_parts.append(f"({key} IS NULL OR {key} = '')")
                            else:
                                where_parts.append(f"{key} = ?")
                                where_values.append(value)
                    
                    where_clause = " AND ".join(where_parts) if where_parts else "1=1"
                    cursor = await self.db._conn.execute(
                        f"DELETE FROM trades WHERE {where_clause}",
                        where_values
                    )
                
                await self.db._conn.commit()
                return DeleteResult(cursor.rowcount)
                
            except Exception as e:
                error_msg = str(e).lower()
                if ("locked" in error_msg or "busy" in error_msg) and attempt < max_retries - 1:
                    logger.warning(f"Database locked while deleting trades, retry {attempt + 1}/{max_retries}...")
                    await asyncio.sleep(retry_delay)
                    retry_delay *= 1.5
                else:
                    logger.error(f"Error deleting trades after {attempt + 1} attempts: {e}")
                    return DeleteResult(0)  # Return 0 instead of raising
        
        return DeleteResult(0)

    async def count_documents(self, query: dict = None):
        """Count trades matching query"""
        try:
            if not query:
                cursor = await self.db._conn.execute("SELECT COUNT(*) FROM trades")
            else:
                where_parts = []
                where_values = []
                for key, value in query.items():
                    where_parts.append(f"{key} = ?")
                    where_values.append(value)
                
                where_clause = " AND ".join(where_parts)
                cursor = await self.db._conn.execute(
                    f"SELECT COUNT(*) FROM trades WHERE {where_clause}",
                    where_values
                )
            
            result = await cursor.fetchone()
            return result[0] if result else 0
        except Exception as e:
            logger.error(f"Error counting trades: {e}")
            return 0


class TradesCursor:
    """MongoDB-like cursor for trades"""
    
    def __init__(self, db: Database, query: dict, projection: dict = None):
        self.db = db
        self.query = query
        self.projection = projection
        self._sort_field = None
        self._sort_direction = None
        self._limit_value = None
    
    def sort(self, field: str, direction: int = 1):
        """Sort results"""
        self._sort_field = field
        self._sort_direction = "ASC" if direction == 1 else "DESC"
        return self
    
    def limit(self, n: int):
        """Limit results"""
        self._limit_value = n
        return self
    
    async def to_list(self, length: int = None) -> List[dict]:
        """Execute query and return list"""
        try:
            # Build WHERE clause - supports $in operator
            where_parts = []
            where_values = []
            for key, value in self.query.items():
                if isinstance(value, dict):
                    # Handle operators
                    for op, op_value in value.items():
                        if op == '$gte':
                            where_parts.append(f"{key} >= ?")
                            where_values.append(op_value.isoformat() if isinstance(op_value, datetime) else op_value)
                        elif op == '$in':
                            # Support $in operator: key IN (?, ?, ?)
                            placeholders = ','.join(['?' for _ in op_value])
                            where_parts.append(f"{key} IN ({placeholders})")
                            where_values.extend(op_value)
                else:
                    where_parts.append(f"{key} = ?")
                    where_values.append(value)
            
            where_clause = " AND ".join(where_parts) if where_parts else "1=1"
            
            # Build query
            sql = f"SELECT * FROM trades WHERE {where_clause}"
            
            if self._sort_field:
                sql += f" ORDER BY {self._sort_field} {self._sort_direction}"
            
            if self._limit_value:
                sql += f" LIMIT {self._limit_value}"
            elif length:
                sql += f" LIMIT {length}"
            
            async with self.db._conn.execute(sql, where_values) as cursor:
                rows = await cursor.fetchall()
                columns = [desc[0] for desc in cursor.description]
                return [dict(zip(columns, row)) for row in rows]
        except Exception as e:
            logger.error(f"Error executing query: {e}")
            return []


class TradeSettings:
    """Trade Settings Collection"""
    
    def __init__(self, db: Database):
        self.db = db
    
    async def find(self, query: dict = None) -> 'TradeSettingsCursor':
        """Find trade settings (MongoDB-like API)"""
        return TradeSettingsCursor(self.db, query or {})
    
    async def find_one(self, query: dict, projection: dict = None) -> Optional[dict]:
        """Find single trade setting"""
        try:
            trade_id = query.get('trade_id')
            if not trade_id:
                return None
            
            async with self.db._conn.execute(
                "SELECT * FROM trade_settings WHERE trade_id = ?",
                (trade_id,)
            ) as cursor:
                row = await cursor.fetchone()
                if row:
                    columns = [desc[0] for desc in cursor.description]
                    return dict(zip(columns, row))
                return None
        except Exception as e:
            logger.error(f"Error fetching trade settings: {e}")
            return None
    
    async def insert_one(self, data: dict):
        """Insert trade settings"""
        try:
            fields = ['trade_id', 'stop_loss', 'take_profit', 'strategy', 
                     'created_at', 'entry_price', 'platform', 'commodity', 'created_by',
                     'status', 'type']
            values = [data.get(f) for f in fields]
            placeholders = ','.join(['?' for _ in fields])
            
            await self.db._conn.execute(
                f"INSERT INTO trade_settings ({','.join(fields)}) VALUES ({placeholders})",
                values
            )
            await self.db._conn.commit()
        except Exception as e:
            logger.error(f"Error inserting trade settings: {e}")
            raise
    
    async def update_one(self, query: dict, update: dict, upsert: bool = False):
        """Update trade settings with EXPLICIT field order and retry logic for SQLite locking"""
        import asyncio
        
        max_retries = 5
        retry_delay = 0.3
        
        for attempt in range(max_retries):
            try:
                trade_id = query.get('trade_id')
                existing = await self.find_one(query)
                
                if existing:
                    # Update with EXPLICIT field order
                    set_data = update.get('$set', {})
                    
                    # CRITICAL FIX: Define fields in EXPLICIT order to prevent confusion
                    # Always process in this order: stop_loss FIRST, then take_profit
                    field_order = ['stop_loss', 'take_profit', 'strategy', 'entry_price', 
                                  'created_at', 'platform', 'commodity', 'created_by', 'status', 'type']
                    
                    set_parts = []
                    set_values = []
                    
                    for field in field_order:
                        if field in set_data:
                            set_parts.append(f"{field} = ?")
                            set_values.append(set_data[field])
                            logger.debug(f"  UPDATE {field} = {set_data[field]}")
                    
                    if set_parts:
                        set_clause = ", ".join(set_parts)
                        set_values.append(trade_id)
                        
                        logger.debug(f"UPDATE SQL: UPDATE trade_settings SET {set_clause} WHERE trade_id = {trade_id}")
                        
                        await self.db._conn.execute(
                            f"UPDATE trade_settings SET {set_clause} WHERE trade_id = ?",
                            set_values
                        )
                elif upsert:
                    # Insert with explicit field order
                    new_data = update.get('$set', {})
                    new_data['trade_id'] = trade_id
                    await self.insert_one(new_data)
                
                await self.db._conn.commit()
                return  # Success, exit retry loop
                
            except Exception as e:
                error_msg = str(e).lower()
                if ("locked" in error_msg or "busy" in error_msg) and attempt < max_retries - 1:
                    logger.warning(f"‚ö†Ô∏è DB locked for trade_settings (attempt {attempt + 1}/{max_retries}), waiting...")
                    await asyncio.sleep(retry_delay)
                    retry_delay *= 1.5  # Exponential backoff
                else:
                    logger.error(f"Error updating trade settings after {attempt + 1} attempts: {e}")
                    raise


class TradeSettingsCursor:
    """MongoDB-like cursor for trade settings"""
    
    def __init__(self, db: Database, query: dict):
        self.db = db
        self.query = query
        self._sort_field = None
        self._sort_direction = "ASC"
        self._limit_value = None
    
    def sort(self, field: str, direction: int = 1):
        """Sort results"""
        self._sort_field = field
        self._sort_direction = "ASC" if direction == 1 else "DESC"
        return self
    
    def limit(self, n: int):
        """Limit results"""
        self._limit_value = n
        return self
    
    async def to_list(self, length: int = None) -> List[dict]:
        """Execute query and return list - supports $in operator"""
        try:
            # Build WHERE clause
            where_parts = []
            where_values = []
            for key, value in self.query.items():
                if isinstance(value, dict):
                    # Handle operators
                    for op, op_value in value.items():
                        if op == '$gte':
                            where_parts.append(f"{key} >= ?")
                            where_values.append(op_value.isoformat() if isinstance(op_value, datetime) else op_value)
                        elif op == '$in':
                            # Support $in operator: key IN (?, ?, ?)
                            placeholders = ','.join(['?' for _ in op_value])
                            where_parts.append(f"{key} IN ({placeholders})")
                            where_values.extend(op_value)
                else:
                    where_parts.append(f"{key} = ?")
                    where_values.append(value)
            
            where_clause = " AND ".join(where_parts) if where_parts else "1=1"
            
            # Build query
            sql = f"SELECT * FROM trade_settings WHERE {where_clause}"
            
            if self._sort_field:
                sql += f" ORDER BY {self._sort_field} {self._sort_direction}"
            
            if self._limit_value:
                sql += f" LIMIT {self._limit_value}"
            elif length:
                sql += f" LIMIT {length}"
            
            async with self.db._conn.execute(sql, where_values) as cursor:
                rows = await cursor.fetchall()
                columns = [desc[0] for desc in cursor.description]
                return [dict(zip(columns, row)) for row in rows]
        except Exception as e:
            logger.error(f"Error executing trade settings query: {e}")
            return []


class MarketData:
    """Market Data Collection"""
    
    def __init__(self, db: Database):
        self.db = db
    
    async def find_one(self, query: dict, projection: dict = None, sort: list = None) -> Optional[dict]:
        """Find market data"""
        try:
            commodity = query.get('commodity')
            if not commodity:
                return None
            
            sql = "SELECT * FROM market_data WHERE commodity = ?"
            
            async with self.db._conn.execute(sql, (commodity,)) as cursor:
                row = await cursor.fetchone()
                if row:
                    columns = [desc[0] for desc in cursor.description]
                    return dict(zip(columns, row))
                return None
        except Exception as e:
            logger.error(f"Error fetching market data: {e}")
            return None
    
    async def find(self, query: dict = None) -> 'MarketDataCursor':
        """Find multiple market data"""
        return MarketDataCursor(self.db, query or {})
    
    async def update_one(self, query: dict, update: dict, upsert: bool = False):
        """Update market data"""
        try:
            commodity = query.get('commodity')
            set_data = update.get('$set', {})
            
            existing = await self.find_one(query)
            
            if existing:
                # Update
                set_parts = []
                set_values = []
                for key, value in set_data.items():
                    set_parts.append(f"{key} = ?")
                    if isinstance(value, datetime):
                        value = value.isoformat()
                    set_values.append(value)
                
                set_clause = ", ".join(set_parts)
                set_values.append(commodity)
                
                await self.db._conn.execute(
                    f"UPDATE market_data SET {set_clause} WHERE commodity = ?",
                    set_values
                )
            elif upsert:
                # Insert - V3.0.0: Added ADX, ATR, Bollinger indicators
                fields = ['commodity', 'timestamp', 'price', 'volume', 'sma_20', 'ema_20',
                         'rsi', 'macd', 'macd_signal', 'macd_histogram', 'trend', 'signal',
                         'data_source', 'adx', 'atr', 'bollinger_upper', 'bollinger_lower', 'bollinger_width']
                values = [set_data.get(f) for f in fields]
                
                # Convert datetime
                if isinstance(values[1], datetime):
                    values[1] = values[1].isoformat()
                
                placeholders = ','.join(['?' for _ in fields])
                
                await self.db._conn.execute(
                    f"INSERT INTO market_data ({','.join(fields)}) VALUES ({placeholders})",
                    values
                )
            
            await self.db._conn.commit()
        except Exception as e:
            logger.error(f"Error updating market data: {e}")
            raise


class MarketDataCursor:
    """Cursor for market data"""
    
    def __init__(self, db: Database, query: dict):
        self.db = db
        self.query = query
    
    async def to_list(self, length: int = None) -> List[dict]:
        """Execute and return list"""
        try:
            sql = "SELECT * FROM market_data"
            if length:
                sql += f" LIMIT {length}"
            
            async with self.db._conn.execute(sql) as cursor:
                rows = await cursor.fetchall()
                columns = [desc[0] for desc in cursor.description]
                return [dict(zip(columns, row)) for row in rows]
        except Exception as e:
            logger.error(f"Error executing market data query: {e}")
            return []


class Stats:
    """Stats Collection for trading statistics"""
    
    def __init__(self, db: Database):
        self.db = db
    
    async def update_one(self, query: dict, update: dict, upsert: bool = False):
        """Update or insert stats"""
        import asyncio
        
        max_retries = 5
        retry_delay = 0.5
        
        for attempt in range(max_retries):
            try:
                set_data = update.get('$set', {})
                
                # Check if stats exist
                async with self.db._conn.execute("SELECT COUNT(*) FROM stats") as cursor:
                    result = await cursor.fetchone()
                    exists = result[0] > 0 if result else False
                
                if exists:
                    # Update existing
                    set_parts = []
                    set_values = []
                    for key, value in set_data.items():
                        set_parts.append(f"{key} = ?")
                        set_values.append(value)
                    
                    if set_parts:
                        set_clause = ", ".join(set_parts)
                        await self.db._conn.execute(f"UPDATE stats SET {set_clause}", set_values)
                elif upsert:
                    # Insert new
                    fields = ['open_positions', 'closed_positions', 'total_profit_loss', 'total_trades']
                    values = [set_data.get(f, 0) for f in fields]
                    placeholders = ','.join(['?' for _ in fields])
                    await self.db._conn.execute(
                        f"INSERT INTO stats ({','.join(fields)}) VALUES ({placeholders})",
                        values
                    )
                
                await self.db._conn.commit()
                break
                
            except Exception as e:
                error_msg = str(e).lower()
                if ("locked" in error_msg or "busy" in error_msg) and attempt < max_retries - 1:
                    await asyncio.sleep(retry_delay)
                    retry_delay *= 1.5
                else:
                    logger.error(f"Error updating stats: {e}")
                    raise


class MarketDataHistory:
    """Market Data History Collection"""
    
    def __init__(self, db: Database):
        self.db = db
    
    async def insert_one(self, data: dict):
        """Insert history entry"""
        try:
            fields = ['commodity_id', 'timestamp', 'price', 'volume', 'sma_20', 'ema_20',
                     'rsi', 'macd', 'macd_signal', 'macd_histogram', 'trend', 'signal']
            values = [data.get(f) for f in fields]
            
            # Convert datetime
            if isinstance(values[1], datetime):
                values[1] = values[1].isoformat()
            
            placeholders = ','.join(['?' for _ in fields])
            
            await self.db._conn.execute(
                f"INSERT INTO market_data_history ({','.join(fields)}) VALUES ({placeholders})",
                values
            )
            await self.db._conn.commit()
        except Exception as e:
            logger.error(f"Error inserting market data history: {e}")
            raise
    
    async def find(self, query: dict) -> 'MarketDataHistoryCursor':
        """Find history entries"""
        return MarketDataHistoryCursor(self.db, query)


class MarketDataHistoryCursor:
    """Cursor for market data history"""
    
    def __init__(self, db: Database, query: dict):
        self.db = db
        self.query = query
        self._sort_field = None
        self._sort_direction = "ASC"
    
    def sort(self, field: str, direction: int = 1):
        """Sort results"""
        self._sort_field = field
        self._sort_direction = "ASC" if direction == 1 else "DESC"
        return self
    
    async def to_list(self, length: int = None) -> List[dict]:
        """Execute and return list"""
        try:
            # Build WHERE
            where_parts = []
            where_values = []
            
            for key, value in self.query.items():
                if isinstance(value, dict):
                    for op, op_value in value.items():
                        if op == '$gte':
                            where_parts.append(f"{key} >= ?")
                            if isinstance(op_value, datetime):
                                op_value = op_value.isoformat()
                            where_values.append(op_value)
                else:
                    where_parts.append(f"{key} = ?")
                    where_values.append(value)
            
            where_clause = " AND ".join(where_parts) if where_parts else "1=1"
            
            sql = f"SELECT * FROM market_data_history WHERE {where_clause}"
            
            if self._sort_field:
                sql += f" ORDER BY {self._sort_field} {self._sort_direction}"
            
            if length:
                sql += f" LIMIT {length}"
            
            async with self.db._conn.execute(sql, where_values) as cursor:
                rows = await cursor.fetchall()
                columns = [desc[0] for desc in cursor.description]
                return [dict(zip(columns, row)) for row in rows]
        except Exception as e:
            logger.error(f"Error executing history query: {e}")
            return []


# ============================================================================
# V2.3.31: MULTI-DATABASE INTEGRATION
# ============================================================================
# Versuche zuerst die neue Multi-DB-Architektur zu laden
# Falls nicht verf√ºgbar, falle auf alte Single-DB zur√ºck

try:
    from database_v2 import (
        db_manager, db, init_database as init_db_v2, 
        close_database as close_db_v2
    )
    
    # Nutze die neuen Wrapper-Klassen
    trading_settings = db_manager.trading_settings
    trades = db_manager.trades
    trade_settings = db_manager.trade_settings
    market_data = db_manager.market_data
    
    # Dummy f√ºr Stats (nicht in neuer DB)
    class DummyStats:
        async def find_one(self, query): return None
        async def update_one(self, query, update, upsert=False): pass
    stats = DummyStats()
    
    # Dummy f√ºr market_data_history
    class DummyMarketHistory:
        async def find(self, query=None): return DummyMarketHistoryCursor()
        async def insert_one(self, data): pass  # V2.3.31: Added insert_one
        async def delete_many(self, query=None): pass
    class DummyMarketHistoryCursor:
        def sort(self, *args): return self
        def limit(self, *args): return self
        async def to_list(self, *args): return []
    market_data_history = DummyMarketHistory()
    
    async def init_database():
        """Initialize multi-database system"""
        await init_db_v2()
        logger.info("‚úÖ Multi-Database System v2.3.31 initialized")
    
    async def close_database():
        """Close multi-database system"""
        await close_db_v2()
    
    logger.info("üöÄ Using Multi-Database Architecture v2.3.31")
    
except ImportError as e:
    logger.warning(f"‚ö†Ô∏è Multi-DB not available, using legacy single-DB: {e}")
    
    # Fallback: Alte Single-DB Architektur
    _db = Database()
    
    # MongoDB-kompatible Collections (Legacy)
    trading_settings = TradingSettings(_db)
    trades = Trades(_db)
    trade_settings = TradeSettings(_db)
    stats = Stats(_db)
    market_data = MarketData(_db)
    market_data_history = MarketDataHistory(_db)
    
    async def init_database():
        """Initialize database connection and schema"""
        await _db.connect()
        await _db.initialize_schema()
        logger.info("‚úÖ Legacy Database initialized")
    
    async def close_database():
        """Close database connection"""
        await _db.close()
